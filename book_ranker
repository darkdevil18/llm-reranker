{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom typing import Optional, List, Dict, Union\nimport logging\nfrom sentence_transformers import SentenceTransformer\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass BookReRanker:\n    def __init__(\n        self,\n        model: Optional[torch.nn.Module] = None,\n        model_name: Optional[str] = \"gpt2\",\n        tokenizer: Optional[object] = None,\n        genre_embedding_model: Optional[object] = None,\n        genre_embedding_model_name: Optional[str] = \"all-MiniLM-L6-v2\",\n        device: Optional[str] = None\n    ):\n        \"\"\"Initialize the book reranker with either model objects or model names.\n        \n        Args:\n            model: Pre-initialized causal language model\n            model_name: Name of the model to load from HuggingFace\n            tokenizer: Pre-initialized tokenizer\n            genre_embedding_model: Pre-initialized sentence transformer model\n            genre_embedding_model_name: Name of sentence transformer model\n            device: Device to use ('cuda' or 'cpu')\n        \"\"\"\n        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        try:\n            self._init_main_model(model, model_name, tokenizer)\n            self._init_genre_model(genre_embedding_model, genre_embedding_model_name)\n            self._init_prompt_templates()\n            logger.info(\"BookReRanker initialized successfully\")\n        except Exception as e:\n            logger.error(f\"Initialization failed: {str(e)}\")\n            raise\n\n    def _init_main_model(self, model: Optional[torch.nn.Module], \n                        model_name: Optional[str], \n                        tokenizer: Optional[object]):\n        \"\"\"Initialize the main language model with error handling.\"\"\"\n        try:\n            if model is not None:\n                if tokenizer is None:\n                    raise ValueError(\"Tokenizer required when passing model object\")\n                self.llm_model = model.to(self.device)\n                self.tokenizer = tokenizer\n                self.model_type = self._detect_model_type(tokenizer)\n            else:\n                if model_name is None:\n                    raise ValueError(\"Either model or model_name must be provided\")\n                self.llm_model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)\n                self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n                if self.tokenizer.pad_token is None:\n                    self.tokenizer.pad_token = self.tokenizer.eos_token\n                self.model_type = self._detect_model_type_from_name(model_name)\n        except Exception as e:\n            logger.error(f\"Failed to initialize main model: {str(e)}\")\n            raise\n\n    def _detect_model_type_from_name(self, model_name: str) -> str:\n        \"\"\"Detect model type from model name for prompt templating.\"\"\"\n        model_name = model_name.lower()\n        if \"gpt\" in model_name:\n            return \"gpt\"\n        elif \"llama\" in model_name or \"mistral\" in model_name:\n            return \"llama\"\n        elif \"phi\" in model_name:\n            return \"gpt\"\n        return \"default\"\n\n    def _detect_model_type(self, tokenizer) -> str:\n        \"\"\"Detect model type from tokenizer configuration.\"\"\"\n        try:\n            if hasattr(tokenizer, \"chat_template\"):\n                if \"llama\" in str(tokenizer.chat_template).lower():\n                    return \"llama\"\n                elif \"gpt\" in str(tokenizer.chat_template).lower():\n                    return \"gpt\"\n            \n            tokenizer_class = str(tokenizer.__class__).lower()\n            if \"llama\" in tokenizer_class:\n                return \"llama\"\n            elif \"gpt\" in tokenizer_class:\n                return \"gpt\"\n            \n            return \"default\"\n        except Exception:\n            return \"default\"\n\n    def _init_genre_model(self, \n                         genre_model: Optional[object], \n                         genre_model_name: Optional[str]):\n        \"\"\"Initialize the genre embedding model.\"\"\"\n        try:\n            if genre_model is not None:\n                self.genre_model = genre_model\n            else:\n                self.genre_model = SentenceTransformer(\n                    genre_model_name or \"all-MiniLM-L6-v2\",\n                    device=self.device\n                )\n        except Exception as e:\n            logger.error(f\"Failed to initialize genre model: {str(e)}\")\n            raise\n\n    def _init_prompt_templates(self):\n        \"\"\"Initialize prompt templates based on model type.\"\"\"\n        self.system_prompt = (\n            \"<<SYS>>\\n\"\n            \"You are a helpful, respectful and honest assistant for book recommendations. \"\n            \"Always answer as helpfully as possible, while being safe. Your recommendations \"\n            \"should not include any harmful or inappropriate content. Please ensure that your \"\n            \"responses are socially unbiased and positive in nature.\\n\"\n            \"<</SYS>>\\n\"\n        )\n        \n        self.prompt_templates = {\n            \"gpt\": \"User Preference: {user_pref}\\nBook: {title}\\nGenres: {genres}\\nDescription: {description}\",\n            \"llama\": (\n                \"[INST] {system_prompt}\\n\"\n                \"Given the user preference: '{user_pref}'\\n\"\n                \"Evaluate this book for recommendation:\\n\"\n                \"Title: {title}\\n\"\n                \"Genres: {genres}\\n\"\n                \"Description: {description}\\n\"\n                \"Provide your evaluation score. [/INST]\"\n            ),\n            \"default\": \"User Preference: {user_pref}\\nBook Information:\\n- Title: {title}\\n- Genres: {genres}\\n- Description: {description}\"\n        }\n\n    def _get_model_specific_prompt(self, user_pref: str, book: Dict) -> str:\n        \"\"\"Generate the appropriate prompt for the current model.\"\"\"\n        try:\n            description = str(book.get('description', ''))[:500]\n            template = self.prompt_templates.get(self.model_type, self.prompt_templates[\"default\"])\n            \n            return template.format(\n                system_prompt=self.system_prompt,\n                user_pref=str(user_pref),\n                title=str(book.get('title', 'Unknown Title')),\n                genres=str(book.get('genres', 'Unknown Genre')),\n                description=description\n            )\n        except Exception as e:\n            logger.warning(f\"Failed to generate prompt: {str(e)}\")\n            return f\"Book: {book.get('title', 'Unknown')}\"\n\n    def _safe_extract(self, data: Dict, key: str, default: Union[float, int], dtype: type) -> Union[float, int]:\n        \"\"\"Safely extract and convert values from dictionary.\"\"\"\n        try:\n            value = data.get(key, default)\n            if value is None:\n                return default\n            return dtype(value)\n        except (ValueError, TypeError):\n            return default\n\n    def _calculate_bayesian_scores(self, books: List[Dict]) -> np.ndarray:\n        \"\"\"Compute Bayesian average ratings with robust error handling.\"\"\"\n        try:\n            if not books:\n                return np.array([])\n            \n            ratings = []\n            counts = []\n            \n            for book in books:\n                rating = self._safe_extract(book, \"average_rating\", 3.5, float)\n                count = self._safe_extract(book, \"ratings_count\", 0, int)\n                ratings.append(rating)\n                counts.append(count)\n            \n            ratings = np.array(ratings, dtype=np.float64)\n            counts = np.array(counts, dtype=np.float64)\n            \n            if len(ratings) == 0:\n                return np.array([])\n            \n            global_avg = np.nanmedian(ratings)\n            min_votes = max(100, int(np.nanmean(counts) * 0.1)) if len(counts) > 0 else 100\n            \n            with np.errstate(divide='ignore', invalid='ignore'):\n                bayesian_scores = (counts / (counts + min_votes)) * ratings\n                bayesian_scores += (min_votes / (counts + min_votes)) * global_avg\n                bayesian_scores[~np.isfinite(bayesian_scores)] = global_avg\n            \n            return bayesian_scores\n        except Exception as e:\n            logger.error(f\"Error in Bayesian score calculation: {str(e)}\")\n            return np.zeros(len(books)) if books else np.array([])\n\n    def _compute_genre_similarity(self, user_pref: str, books: List[Dict]) -> np.ndarray:\n        \"\"\"Calculate genre similarity scores.\"\"\"\n        try:\n            if not books:\n                return np.array([])\n                \n            genre_texts = []\n            for book in books:\n                genres = str(book.get('genres', ''))\n                genre_texts.append(genres)\n            \n            genre_embeds = self.genre_model.encode(genre_texts)\n            user_embed = self.genre_model.encode(str(user_pref))\n            return cosine_similarity(user_embed.reshape(1, -1), genre_embeds)[0]\n        except Exception as e:\n            logger.error(f\"Error in genre similarity calculation: {str(e)}\")\n            return np.zeros(len(books)) if books else np.array([])\n\n    def _compute_nll_scores(self, user_pref: str, books: List[Dict]) -> List[float]:\n        \"\"\"Calculate negative log-likelihood scores with error handling.\"\"\"\n        nll_scores = []\n        if not books:\n            return nll_scores\n            \n        for book in books:\n            try:\n                text = self._get_model_specific_prompt(user_pref, book)\n                inputs = self.tokenizer(\n                    text,\n                    return_tensors=\"pt\",\n                    truncation=True,\n                    max_length=512,\n                    padding=True\n                ).to(self.device)\n                \n                with torch.no_grad():\n                    outputs = self.llm_model(**inputs, labels=inputs[\"input_ids\"])\n                    nll = -outputs.logits.log_softmax(dim=-1)\\\n                                   .gather(-1, inputs[\"input_ids\"].unsqueeze(-1))\\\n                                   .mean().item()\n                nll_scores.append(nll)\n            except Exception as e:\n                logger.warning(f\"Error processing book {book.get('title')}: {str(e)}\")\n                nll_scores.append(10.0)  # High penalty for failed processing\n        \n        return nll_scores\n\n    def _normalize_scores(self, scores: np.ndarray, higher_better: bool = False) -> np.ndarray:\n        \"\"\"Normalize scores to [0, 1] range.\"\"\"\n        try:\n            scores = np.array(scores, dtype=np.float64)\n            if len(scores) == 0:\n                return scores\n                \n            min_val = np.nanmin(scores)\n            max_val = np.nanmax(scores)\n            \n            if np.isclose(min_val, max_val):\n                return np.ones_like(scores) if higher_better else np.zeros_like(scores)\n                \n            if higher_better:\n                return (scores - min_val) / (max_val - min_val + 1e-8)\n            else:\n                return 1 - (scores - min_val) / (max_val - min_val + 1e-8)\n        except Exception as e:\n            logger.error(f\"Error normalizing scores: {str(e)}\")\n            return np.zeros_like(scores)\n\n    def _combine_scores(self, \n                       nll_scores: List[float], \n                       genre_scores: np.ndarray, \n                       rating_scores: np.ndarray, \n                       weights: tuple) -> np.ndarray:\n        \"\"\"Combine normalized scores with given weights.\"\"\"\n        try:\n            weights = np.array(weights, dtype=np.float64)\n            weights = weights / weights.sum()  # Normalize weights\n            \n            nll_normalized = self._normalize_scores(nll_scores)\n            genre_normalized = self._normalize_scores(genre_scores, higher_better=True)\n            rating_normalized = self._normalize_scores(rating_scores, higher_better=True)\n            \n            return (weights[0] * nll_normalized + \n                    weights[1] * genre_normalized + \n                    weights[2] * rating_normalized)\n        except Exception as e:\n            logger.error(f\"Error combining scores: {str(e)}\")\n            return np.zeros(len(nll_scores)) if nll_scores else np.array([])\n\n    def rerank(\n        self,\n        user_pref: str,\n        book_batch: List[Dict],\n        top_k: Optional[int] = None,\n        weights: tuple = (0.6, 0.3, 0.1)\n    ) -> List[Dict]:\n        \"\"\"Main reranking method with comprehensive error handling.\n        \n        Args:\n            user_pref: User preference text\n            book_batch: List of book dictionaries\n            top_k: Number of top results to return (None for all)\n            weights: Tuple of weights for (NLL, Genre, Rating)\n            \n        Returns:\n            List of ranked book dictionaries\n        \"\"\"\n        try:\n            # Input validation\n            if not isinstance(book_batch, list):\n                raise ValueError(\"book_batch must be a list\")\n                \n            if not book_batch:\n                return []\n                \n            if not all(isinstance(b, dict) for b in book_batch):\n                raise ValueError(\"All items in book_batch must be dictionaries\")\n                \n            if not isinstance(user_pref, str):\n                raise ValueError(\"user_pref must be a string\")\n                \n            # Calculate scores\n            genre_scores = self._compute_genre_similarity(user_pref, book_batch)\n            nll_scores = self._compute_nll_scores(user_pref, book_batch)\n            rating_scores = self._calculate_bayesian_scores(book_batch)\n            \n            # Ensure all scores have the same length\n            min_length = min(len(genre_scores), len(nll_scores), len(rating_scores))\n            combined_scores = self._combine_scores(\n                nll_scores[:min_length],\n                genre_scores[:min_length],\n                rating_scores[:min_length],\n                weights\n            )\n            \n            # Determine top_k\n            if top_k is None or top_k <= 0:\n                top_k = len(combined_scores)\n            top_k = min(top_k, len(combined_scores))\n            \n            # Return ranked results\n            ranked_indices = np.argsort(combined_scores)[::-1][:top_k]\n            return [book_batch[i] for i in ranked_indices]\n            \n        except Exception as e:\n            logger.error(f\"Reranking failed: {str(e)}\")\n            return book_batch[:top_k] if book_batch else []","metadata":{"_uuid":"2a7900b8-6a94-4526-8119-831014474609","_cell_guid":"e769cfe2-d1eb-4cf7-bd5b-9b9919f227b0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}